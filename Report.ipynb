{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as pl\n",
    "\n",
    "import scipy.io.wavfile as wav\n",
    "from scikits.talkbox.features import mfcc\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "BASE_DIR = 'vowels/'\n",
    "files = os.listdir(BASE_DIR)\n",
    "\n",
    "import mlp_backprop_momentum as mlp\n",
    "reload(mlp)\n",
    "import k_fold_cross_validation as cv\n",
    "reload(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nafFiles = []\n",
    "namFiles = []\n",
    "\n",
    "# Get all natural female and male wav files by itering all the files' names.\n",
    "# The first value of each array's elements is the simple rate, while the second one is the values.\n",
    "for f in files:\n",
    "    if f.startswith(\"naf\"):\n",
    "        nafFiles.append(wav.read(BASE_DIR + f))\n",
    "    if f.startswith(\"nam\"):\n",
    "        namFiles.append(wav.read(BASE_DIR + f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nafCeps = []\n",
    "for f in nafFiles:\n",
    "    nafCeps.append(mfcc(f[1], fs=f[0])[0])\n",
    "\n",
    "namCeps = []\n",
    "for f in namFiles:\n",
    "    namCeps.append(mfcc(f[1], fs=f[0])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, pour chaque fichier, plutôt que de garder toutes les valeurs, on applatit les valeurs pour ne garder que la moyenne afin d'avoir des temps de calculs moins longs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nafMeanCeps = []\n",
    "for c in nafCeps:\n",
    "    nafMeanCeps.append(np.mean(c, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "namMeanCeps = []\n",
    "for c in namCeps:\n",
    "    namMeanCeps.append(np.mean(c, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée le dataset à partir des valeurs de mfcc, on choisit 1 pour les femmes et -1 pour les hommes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dsf = np.array(map(lambda x: np.append(x, 1), nafMeanCeps))\n",
    "dsm = np.array(map(lambda x: np.append(x, -1), namMeanCeps))\n",
    "dataset = np.append(dsf, dsm, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_INITS = 10\n",
    "EPOCHS = 100\n",
    "N_NEURONS = [2, 4, 8, 16, 32]\n",
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE = np.zeros((len(N_NEURONS), N_INITS, EPOCHS))\n",
    "\n",
    "for i_h, h in enumerate(N_NEURONS):                                     # looping the number of hidden neurons\n",
    "    print 'Testing', h, 'neurons...'\n",
    "    nn = mlp.MLP([13,h,2], 'tanh')\n",
    "    for i in np.arange(N_INITS):                                        # looping the initializations\n",
    "        nn.init_weights()\n",
    "        \n",
    "        MSE[i_h, i, :] = nn.fit((dataset[:,0:13], dataset[:,13:15]),\n",
    "                                learning_rate=LEARNING_RATE,\n",
    "                                momentum=MOMENTUM,\n",
    "                                epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pl.figure(figsize=(15,12))\n",
    "p_count = 0\n",
    "for lim in [100, 50, 20]:\n",
    "    for n in np.arange(MSE.shape[0]):\n",
    "        p_count += 1\n",
    "        pl.subplot(3,MSE.shape[0], p_count)\n",
    "        for i in np.arange(MSE.shape[1]):\n",
    "            pl.plot(MSE[n,i,:], c='b')\n",
    "        pl.ylim(0,1)\n",
    "        pl.xlim(0,lim)\n",
    "        pl.xlabel('Epochs')\n",
    "        pl.ylabel('MSE')\n",
    "        pl.title(str(N_NEURONS[n]) + ' neurons')\n",
    "        pl.grid()\n",
    "pl.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces graphs montrent qu'après environ 50 epochs l'amélioration n'est pas substentielle et qu'il n'est pas nécessaire d'avoir plus de 8 neurones pour avoir des résultats corrects. Par contre, avec un faible nombre d'epochs, l'impact du nombre de neurones est plus grand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the number of hidden neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = [20, 50, 100]\n",
    "K = 5\n",
    "N_TESTS = 10\n",
    "N_NEURONS = [2, 4, 6, 8, 10, 15, 20, 30, 40, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE_train = np.zeros((len(N_NEURONS), len(EPOCHS), N_TESTS))\n",
    "MSE_test = np.zeros((len(N_NEURONS), len(EPOCHS), N_TESTS))\n",
    "\n",
    "for i_e, e in enumerate(EPOCHS):                                            # looping the number of epochs\n",
    "    print 'Testing with', e, 'epochs...'\n",
    "    for i_h, h in enumerate(N_NEURONS):                                     # looping the number of hidden neurons\n",
    "        print '\\tTesting', h, 'neurons...'\n",
    "        nn = mlp.MLP([13,h,1], 'tanh')\n",
    "        for i in np.arange(N_TESTS):                                        # looping the tests\n",
    "            temp1, temp2 = cv.k_fold_cross_validation(nn,\n",
    "                                                      dataset,\n",
    "                                                      k=K,\n",
    "                                                      learning_rate=LEARNING_RATE,\n",
    "                                                      momentum=MOMENTUM,\n",
    "                                                      epochs=e)\n",
    "            MSE_train[i_h, i_e, i] = temp1\n",
    "            MSE_test[i_h, i_e, i] = temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE_train_mean = np.mean(MSE_train, axis=2)\n",
    "MSE_test_mean = np.mean(MSE_test, axis=2)\n",
    "MSE_train_sd = np.std(MSE_train, axis=2)\n",
    "MSE_test_sd = np.std(MSE_test, axis=2)\n",
    "\n",
    "v_min = min(np.min(MSE_train_mean), np.min(MSE_test_mean))\n",
    "v_max = max(np.max(MSE_train_mean), np.max(MSE_test_mean))\n",
    "\n",
    "pl.figure(figsize=(15,6))\n",
    "for i_e, e in enumerate(EPOCHS):\n",
    "    pl.subplot(1,3,i_e+1)\n",
    "    pl.fill_between(N_NEURONS, MSE_train_mean[:,i_e], MSE_train_mean[:,i_e]+MSE_train_sd[:,i_e], facecolor='blue', alpha=0.5, label='Train')\n",
    "    pl.fill_between(N_NEURONS, MSE_train_mean[:,i_e], MSE_train_mean[:,i_e]-MSE_train_sd[:,i_e], facecolor='blue', alpha=0.5)\n",
    "    pl.fill_between(N_NEURONS, MSE_test_mean[:,i_e], MSE_test_mean[:,i_e]+MSE_test_sd[:,i_e], facecolor='red', alpha=0.5, label='Test')\n",
    "    pl.fill_between(N_NEURONS, MSE_test_mean[:,i_e], MSE_test_mean[:,i_e]-MSE_test_sd[:,i_e], facecolor='red', alpha=0.5)\n",
    "    pl.ylim(0.95*v_min,1.05*v_max)\n",
    "    pl.ylabel('MSE')\n",
    "    pl.xlabel('Number of hidden neurons')\n",
    "    pl.title(str(K)+'-fold cross-validation with '+str(e)+' epochs')\n",
    "    pl.legend()\n",
    "    pl.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que quand le nombre d'epochs est faible, le training set donne des résultats proche du testing set et que plus le nombre de neurones augmente plus les résultats sont bons. Par contre avec suffisament d'epochs l'augmentation du nombres de neurones a peu d'effet et le testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the number of epochs and the number of hidden neurons at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE_train = np.zeros((len(N_NEURONS), EPOCHS))\n",
    "MSE_test = np.zeros((len(N_NEURONS), EPOCHS))\n",
    "\n",
    "for i_h, h in enumerate(N_NEURONS):                                     # looping the number of hidden neurons\n",
    "    print '\\tTesting', h, 'neurons...'\n",
    "    nn = mlp.MLP([13,h,1], 'tanh')\n",
    "    temp1, temp2 = cv.k_fold_cross_validation_per_epoch(nn,\n",
    "                                                        dataset,\n",
    "                                                        k=K,\n",
    "                                                        learning_rate=LEARNING_RATE,\n",
    "                                                        momentum=MOMENTUM,\n",
    "                                                        epochs=EPOCHS)\n",
    "    MSE_train[i_h, :] = temp1\n",
    "    MSE_test[i_h, :] = temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min(np.min(MSE_train), np.min(MSE_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#v_min = min(np.min(MSE_train), np.min(MSE_test))\n",
    "v_min = 0.1   # tune these values to enhance visualization\n",
    "v_max = 1\n",
    "\n",
    "pl.figure(figsize=(15,8))\n",
    "pl.subplot(2,1,1)\n",
    "pl.imshow(MSE_train, vmin=v_min, vmax=v_max, aspect=3, interpolation='nearest')\n",
    "pl.yticks(np.arange(len(N_NEURONS)), N_NEURONS)\n",
    "pl.xlabel('Epochs')\n",
    "pl.ylabel('Number of hidden Neurons')\n",
    "pl.title('Training')\n",
    "pl.colorbar()\n",
    "pl.subplot(2,1,2)\n",
    "pl.imshow(MSE_test, vmin=v_min, vmax=v_max, aspect=3, interpolation='nearest')\n",
    "pl.yticks(np.arange(len(N_NEURONS)), N_NEURONS)\n",
    "pl.xlabel('Epochs')\n",
    "pl.ylabel('Number of hidden Neurons')\n",
    "pl.title('Test')\n",
    "pl.colorbar()\n",
    "pl.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sans surprise par rapport aux graphs précédents, on voit que plus le nombre d'epochs et de neurones augmente, plus l'erreur est faible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MSE_train, MSE_test, conf_mat = cv.k_fold_cross_validation(nn,\n",
    "                                                          dataset,\n",
    "                                                          k=K,\n",
    "                                                          learning_rate=LEARNING_RATE,\n",
    "                                                          momentum=MOMENTUM,\n",
    "                                                          epochs=80,\n",
    "                                                          threshold=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'MSE training: ', MSE_train\n",
    "print 'MSE test: ', MSE_test\n",
    "print 'Confusion matrix:'\n",
    "print conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le fait que l'erreur est basse signifie que les données sont faciles à différencier, ce qui semble normal entre une voix d'homme et de femme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nkFiles = []\n",
    "\n",
    "for f in files:\n",
    "    if f.startswith(\"nk\"):\n",
    "        nkFiles.append(wav.read(BASE_DIR + f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nkCeps = []\n",
    "for f in nkFiles:\n",
    "    nkCeps.append(mfcc(f[1], fs=f[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nkMeanCeps = []\n",
    "for c in nkCeps:\n",
    "    nkMeanCeps.append(np.mean(c, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dsf = np.array(map(lambda x: np.append(x, 1), nkMeanCeps))\n",
    "dsm = np.array(map(lambda x: np.append(x, -1), namMeanCeps))\n",
    "dataset = np.append(dsf, dsm, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_INITS = 10\n",
    "EPOCHS = 100\n",
    "N_NEURONS = [2, 4, 8, 16, 32]\n",
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE = np.zeros((len(N_NEURONS), N_INITS, EPOCHS))\n",
    "\n",
    "for i_h, h in enumerate(N_NEURONS):                                     # looping the number of hidden neurons\n",
    "    print 'Testing', h, 'neurons...'\n",
    "    nn = mlp.MLP([13,h,2], 'tanh')\n",
    "    for i in np.arange(N_INITS):                                        # looping the initializations\n",
    "        nn.init_weights()\n",
    "        \n",
    "        MSE[i_h, i, :] = nn.fit((dataset[:,0:13], dataset[:,13:15]),\n",
    "                                learning_rate=LEARNING_RATE,\n",
    "                                momentum=MOMENTUM,\n",
    "                                epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pl.figure(figsize=(15,12))\n",
    "p_count = 0\n",
    "for lim in [100, 50, 20]:\n",
    "    for n in np.arange(MSE.shape[0]):\n",
    "        p_count += 1\n",
    "        pl.subplot(3,MSE.shape[0], p_count)\n",
    "        for i in np.arange(MSE.shape[1]):\n",
    "            pl.plot(MSE[n,i,:], c='b')\n",
    "        pl.ylim(0,1)\n",
    "        pl.xlim(0,lim)\n",
    "        pl.xlabel('Epochs')\n",
    "        pl.ylabel('MSE')\n",
    "        pl.title(str(N_NEURONS[n]) + ' neurons')\n",
    "        pl.grid()\n",
    "pl.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit ici que le dataset doit être facile à différencier, puisqu'avec seulement 4 neurones et environ 50 epochs on obtient déjà de très bon résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the number of hidden neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = [20, 50, 100]\n",
    "K = 5\n",
    "N_TESTS = 10\n",
    "N_NEURONS = [2, 4, 6, 8, 10, 15, 20, 30, 40, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE_train = np.zeros((len(N_NEURONS), len(EPOCHS), N_TESTS))\n",
    "MSE_test = np.zeros((len(N_NEURONS), len(EPOCHS), N_TESTS))\n",
    "\n",
    "for i_e, e in enumerate(EPOCHS):                                            # looping the number of epochs\n",
    "    print 'Testing with', e, 'epochs...'\n",
    "    for i_h, h in enumerate(N_NEURONS):                                     # looping the number of hidden neurons\n",
    "        print '\\tTesting', h, 'neurons...'\n",
    "        nn = mlp.MLP([13,h,1], 'tanh')\n",
    "        for i in np.arange(N_TESTS):                                        # looping the tests\n",
    "            temp1, temp2 = cv.k_fold_cross_validation(nn,\n",
    "                                                      dataset,\n",
    "                                                      k=K,\n",
    "                                                      learning_rate=LEARNING_RATE,\n",
    "                                                      momentum=MOMENTUM,\n",
    "                                                      epochs=e)\n",
    "            MSE_train[i_h, i_e, i] = temp1\n",
    "            MSE_test[i_h, i_e, i] = temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE_train_mean = np.mean(MSE_train, axis=2)\n",
    "MSE_test_mean = np.mean(MSE_test, axis=2)\n",
    "MSE_train_sd = np.std(MSE_train, axis=2)\n",
    "MSE_test_sd = np.std(MSE_test, axis=2)\n",
    "\n",
    "v_min = min(np.min(MSE_train_mean), np.min(MSE_test_mean))\n",
    "v_max = max(np.max(MSE_train_mean), np.max(MSE_test_mean))\n",
    "\n",
    "pl.figure(figsize=(15,6))\n",
    "for i_e, e in enumerate(EPOCHS):\n",
    "    pl.subplot(1,3,i_e+1)\n",
    "    pl.fill_between(N_NEURONS, MSE_train_mean[:,i_e], MSE_train_mean[:,i_e]+MSE_train_sd[:,i_e], facecolor='blue', alpha=0.5, label='Train')\n",
    "    pl.fill_between(N_NEURONS, MSE_train_mean[:,i_e], MSE_train_mean[:,i_e]-MSE_train_sd[:,i_e], facecolor='blue', alpha=0.5)\n",
    "    pl.fill_between(N_NEURONS, MSE_test_mean[:,i_e], MSE_test_mean[:,i_e]+MSE_test_sd[:,i_e], facecolor='red', alpha=0.5, label='Test')\n",
    "    pl.fill_between(N_NEURONS, MSE_test_mean[:,i_e], MSE_test_mean[:,i_e]-MSE_test_sd[:,i_e], facecolor='red', alpha=0.5)\n",
    "    pl.ylim(0.95*v_min,1.05*v_max)\n",
    "    pl.ylabel('MSE')\n",
    "    pl.xlabel('Number of hidden neurons')\n",
    "    pl.title(str(K)+'-fold cross-validation with '+str(e)+' epochs')\n",
    "    pl.legend()\n",
    "    pl.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le troisième graphe montre bien que le nombre de neurones n'influe presque pas sur les résultats puisque l'erreur reste constante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the number of epochs and the number of hidden neurons at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE_train = np.zeros((len(N_NEURONS), EPOCHS))\n",
    "MSE_test = np.zeros((len(N_NEURONS), EPOCHS))\n",
    "\n",
    "for i_h, h in enumerate(N_NEURONS):                                     # looping the number of hidden neurons\n",
    "    print '\\tTesting', h, 'neurons...'\n",
    "    nn = mlp.MLP([13,h,1], 'tanh')\n",
    "    temp1, temp2 = cv.k_fold_cross_validation_per_epoch(nn,\n",
    "                                                        dataset,\n",
    "                                                        k=K,\n",
    "                                                        learning_rate=LEARNING_RATE,\n",
    "                                                        momentum=MOMENTUM,\n",
    "                                                        epochs=EPOCHS)\n",
    "    MSE_train[i_h, :] = temp1\n",
    "    MSE_test[i_h, :] = temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min(np.min(MSE_train), np.min(MSE_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#v_min = min(np.min(MSE_train), np.min(MSE_test))\n",
    "v_min = 0.05   # tune these values to enhance visualization\n",
    "v_max = 0.5\n",
    "\n",
    "pl.figure(figsize=(15,8))\n",
    "pl.subplot(2,1,1)\n",
    "pl.imshow(MSE_train, vmin=v_min, vmax=v_max, aspect=3, interpolation='nearest')\n",
    "pl.yticks(np.arange(len(N_NEURONS)), N_NEURONS)\n",
    "pl.xlabel('Epochs')\n",
    "pl.ylabel('Number of hidden Neurons')\n",
    "pl.title('Training')\n",
    "pl.colorbar()\n",
    "pl.subplot(2,1,2)\n",
    "pl.imshow(MSE_test, vmin=v_min, vmax=v_max, aspect=3, interpolation='nearest')\n",
    "pl.yticks(np.arange(len(N_NEURONS)), N_NEURONS)\n",
    "pl.xlabel('Epochs')\n",
    "pl.ylabel('Number of hidden Neurons')\n",
    "pl.title('Test')\n",
    "pl.colorbar()\n",
    "pl.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La séparation entre la zone rouge et la zone blue est très nette, ce qui signifie qu'il n'y a peu de faux positifs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MSE_train, MSE_test, conf_mat = cv.k_fold_cross_validation(nn,\n",
    "                                                          dataset,\n",
    "                                                          k=K,\n",
    "                                                          learning_rate=LEARNING_RATE,\n",
    "                                                          momentum=MOMENTUM,\n",
    "                                                          epochs=80,\n",
    "                                                          threshold=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'MSE training: ', MSE_train\n",
    "print 'MSE test: ', MSE_test\n",
    "print 'Confusion matrix:'\n",
    "print conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats obtenus sont vraiment excellents, ce qui montre bien qu'il est facile de différencier une voix d'homme adulte d'une voix d'enfant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dsf = np.array(map(lambda x: np.append(x, 1), nafMeanCeps))\n",
    "dsm = np.array(map(lambda x: np.append(x, -1), nkMeanCeps))\n",
    "dataset = np.append(dsf, dsm, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_INITS = 10\n",
    "EPOCHS = 100\n",
    "N_NEURONS = [2, 4, 8, 16, 32]\n",
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE = np.zeros((len(N_NEURONS), N_INITS, EPOCHS))\n",
    "\n",
    "for i_h, h in enumerate(N_NEURONS):                                     # looping the number of hidden neurons\n",
    "    print 'Testing', h, 'neurons...'\n",
    "    nn = mlp.MLP([13,h,2], 'tanh')\n",
    "    for i in np.arange(N_INITS):                                        # looping the initializations\n",
    "        nn.init_weights()\n",
    "        \n",
    "        MSE[i_h, i, :] = nn.fit((dataset[:,0:13], dataset[:,13:15]),\n",
    "                                learning_rate=LEARNING_RATE,\n",
    "                                momentum=MOMENTUM,\n",
    "                                epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pl.figure(figsize=(15,12))\n",
    "p_count = 0\n",
    "for lim in [100, 50, 20]:\n",
    "    for n in np.arange(MSE.shape[0]):\n",
    "        p_count += 1\n",
    "        pl.subplot(3,MSE.shape[0], p_count)\n",
    "        for i in np.arange(MSE.shape[1]):\n",
    "            pl.plot(MSE[n,i,:], c='b')\n",
    "        pl.ylim(0,1)\n",
    "        pl.xlim(0,lim)\n",
    "        pl.xlabel('Epochs')\n",
    "        pl.ylabel('MSE')\n",
    "        pl.title(str(N_NEURONS[n]) + ' neurons')\n",
    "        pl.grid()\n",
    "pl.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que les graphs sont relativement plats, ce qui signifie que le nombre d'epochs n'a pas une grande influence. A nouveau, vers 60 epochs les résultats sont déjà très bons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the number of hidden neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = [20, 50, 100]\n",
    "K = 5\n",
    "N_TESTS = 10\n",
    "N_NEURONS = [2, 4, 6, 8, 10, 15, 20, 30, 40, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE_train = np.zeros((len(N_NEURONS), len(EPOCHS), N_TESTS))\n",
    "MSE_test = np.zeros((len(N_NEURONS), len(EPOCHS), N_TESTS))\n",
    "\n",
    "for i_e, e in enumerate(EPOCHS):                                            # looping the number of epochs\n",
    "    print 'Testing with', e, 'epochs...'\n",
    "    for i_h, h in enumerate(N_NEURONS):                                     # looping the number of hidden neurons\n",
    "        print '\\tTesting', h, 'neurons...'\n",
    "        nn = mlp.MLP([13,h,1], 'tanh')\n",
    "        for i in np.arange(N_TESTS):                                        # looping the tests\n",
    "            temp1, temp2 = cv.k_fold_cross_validation(nn,\n",
    "                                                      dataset,\n",
    "                                                      k=K,\n",
    "                                                      learning_rate=LEARNING_RATE,\n",
    "                                                      momentum=MOMENTUM,\n",
    "                                                      epochs=e)\n",
    "            MSE_train[i_h, i_e, i] = temp1\n",
    "            MSE_test[i_h, i_e, i] = temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE_train_mean = np.mean(MSE_train, axis=2)\n",
    "MSE_test_mean = np.mean(MSE_test, axis=2)\n",
    "MSE_train_sd = np.std(MSE_train, axis=2)\n",
    "MSE_test_sd = np.std(MSE_test, axis=2)\n",
    "\n",
    "v_min = min(np.min(MSE_train_mean), np.min(MSE_test_mean))\n",
    "v_max = max(np.max(MSE_train_mean), np.max(MSE_test_mean))\n",
    "\n",
    "pl.figure(figsize=(15,6))\n",
    "for i_e, e in enumerate(EPOCHS):\n",
    "    pl.subplot(1,3,i_e+1)\n",
    "    pl.fill_between(N_NEURONS, MSE_train_mean[:,i_e], MSE_train_mean[:,i_e]+MSE_train_sd[:,i_e], facecolor='blue', alpha=0.5, label='Train')\n",
    "    pl.fill_between(N_NEURONS, MSE_train_mean[:,i_e], MSE_train_mean[:,i_e]-MSE_train_sd[:,i_e], facecolor='blue', alpha=0.5)\n",
    "    pl.fill_between(N_NEURONS, MSE_test_mean[:,i_e], MSE_test_mean[:,i_e]+MSE_test_sd[:,i_e], facecolor='red', alpha=0.5, label='Test')\n",
    "    pl.fill_between(N_NEURONS, MSE_test_mean[:,i_e], MSE_test_mean[:,i_e]-MSE_test_sd[:,i_e], facecolor='red', alpha=0.5)\n",
    "    pl.ylim(0.95*v_min,1.05*v_max)\n",
    "    pl.ylabel('MSE')\n",
    "    pl.xlabel('Number of hidden neurons')\n",
    "    pl.title(str(K)+'-fold cross-validation with '+str(e)+' epochs')\n",
    "    pl.legend()\n",
    "    pl.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout comme pour le nombre d'epochs, le nombre de neurones n'a vite plus plus d'impact sur la précision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the number of epochs and the number of hidden neurons at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE_train = np.zeros((len(N_NEURONS), EPOCHS))\n",
    "MSE_test = np.zeros((len(N_NEURONS), EPOCHS))\n",
    "\n",
    "for i_h, h in enumerate(N_NEURONS):                                     # looping the number of hidden neurons\n",
    "    print '\\tTesting', h, 'neurons...'\n",
    "    nn = mlp.MLP([13,h,1], 'tanh')\n",
    "    temp1, temp2 = cv.k_fold_cross_validation_per_epoch(nn,\n",
    "                                                        dataset,\n",
    "                                                        k=K,\n",
    "                                                        learning_rate=LEARNING_RATE,\n",
    "                                                        momentum=MOMENTUM,\n",
    "                                                        epochs=EPOCHS)\n",
    "    MSE_train[i_h, :] = temp1\n",
    "    MSE_test[i_h, :] = temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min(np.min(MSE_train), np.min(MSE_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#v_min = min(np.min(MSE_train), np.min(MSE_test))\n",
    "v_min = 0.1   # tune these values to enhance visualization\n",
    "v_max = 0.5\n",
    "\n",
    "pl.figure(figsize=(15,8))\n",
    "pl.subplot(2,1,1)\n",
    "pl.imshow(MSE_train, vmin=v_min, vmax=v_max, aspect=3, interpolation='nearest')\n",
    "pl.yticks(np.arange(len(N_NEURONS)), N_NEURONS)\n",
    "pl.xlabel('Epochs')\n",
    "pl.ylabel('Number of hidden Neurons')\n",
    "pl.title('Training')\n",
    "pl.colorbar()\n",
    "pl.subplot(2,1,2)\n",
    "pl.imshow(MSE_test, vmin=v_min, vmax=v_max, aspect=3, interpolation='nearest')\n",
    "pl.yticks(np.arange(len(N_NEURONS)), N_NEURONS)\n",
    "pl.xlabel('Epochs')\n",
    "pl.ylabel('Number of hidden Neurons')\n",
    "pl.title('Test')\n",
    "pl.colorbar()\n",
    "pl.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le faible tau de zones bleu foncé montre qu'il y a relativement beaucoup de faux positifs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MSE_train, MSE_test, conf_mat = cv.k_fold_cross_validation(nn,\n",
    "                                                          dataset,\n",
    "                                                          k=K,\n",
    "                                                          learning_rate=LEARNING_RATE,\n",
    "                                                          momentum=MOMENTUM,\n",
    "                                                          epochs=80,\n",
    "                                                          threshold=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'MSE training: ', MSE_train\n",
    "print 'MSE test: ', MSE_test\n",
    "print 'Confusion matrix:'\n",
    "print conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'erreur est relativement élevée ce qui montre bien qu'une voix de femme est relativement proche d'une voix d'enfant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "naturalFiles = []\n",
    "synthesizedFiles = []\n",
    "\n",
    "for f in files:\n",
    "    if \"n\" in f:\n",
    "        naturalFiles.append(wav.read(BASE_DIR + f))\n",
    "    if \"s\" in f:\n",
    "        synthesizedFiles.append(wav.read(BASE_DIR + f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "naturalCeps = []\n",
    "for f in naturalFiles:\n",
    "    naturalCeps.append(mfcc(f[1], fs=f[0])[0])\n",
    "\n",
    "synthesizedCeps = []\n",
    "for f in synthesizedFiles:\n",
    "    synthesizedCeps.append(mfcc(f[1], fs=f[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "naturalMeanCeps = []\n",
    "for c in naturalCeps:\n",
    "    naturalMeanCeps.append(np.mean(c, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "synthesizedMeanCeps = []\n",
    "for c in synthesizedCeps:\n",
    "    synthesizedMeanCeps.append(np.mean(c, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dsf = np.array(map(lambda x: np.append(x, 1), naturalMeanCeps))\n",
    "dsm = np.array(map(lambda x: np.append(x, -1), synthesizedMeanCeps))\n",
    "dataset = np.append(dsf, dsm, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_INITS = 10\n",
    "EPOCHS = 100\n",
    "N_NEURONS = [2, 4, 8, 16, 32]\n",
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE = np.zeros((len(N_NEURONS), N_INITS, EPOCHS))\n",
    "\n",
    "for i_h, h in enumerate(N_NEURONS):                                     # looping the number of hidden neurons\n",
    "    print 'Testing', h, 'neurons...'\n",
    "    nn = mlp.MLP([13,h,2], 'tanh')\n",
    "    for i in np.arange(N_INITS):                                        # looping the initializations\n",
    "        nn.init_weights()\n",
    "        \n",
    "        MSE[i_h, i, :] = nn.fit((dataset[:,0:13], dataset[:,13:15]),\n",
    "                                learning_rate=LEARNING_RATE,\n",
    "                                momentum=MOMENTUM,\n",
    "                                epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pl.figure(figsize=(15,12))\n",
    "p_count = 0\n",
    "for lim in [100, 50, 20]:\n",
    "    for n in np.arange(MSE.shape[0]):\n",
    "        p_count += 1\n",
    "        pl.subplot(3,MSE.shape[0], p_count)\n",
    "        for i in np.arange(MSE.shape[1]):\n",
    "            pl.plot(MSE[n,i,:], c='b')\n",
    "        pl.ylim(0,1)\n",
    "        pl.xlim(0,lim)\n",
    "        pl.xlabel('Epochs')\n",
    "        pl.ylabel('MSE')\n",
    "        pl.title(str(N_NEURONS[n]) + ' neurons')\n",
    "        pl.grid()\n",
    "pl.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nombre d'epochs a peut d'influence sur l'erreur, à 50 epochs les résultats sont à peine meilleurs qu'à 20 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the number of hidden neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = [20, 50, 100]\n",
    "K = 5\n",
    "N_TESTS = 10\n",
    "N_NEURONS = [2, 4, 6, 8, 10, 15, 20, 30, 40, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE_train = np.zeros((len(N_NEURONS), len(EPOCHS), N_TESTS))\n",
    "MSE_test = np.zeros((len(N_NEURONS), len(EPOCHS), N_TESTS))\n",
    "\n",
    "for i_e, e in enumerate(EPOCHS):                                            # looping the number of epochs\n",
    "    print 'Testing with', e, 'epochs...'\n",
    "    for i_h, h in enumerate(N_NEURONS):                                     # looping the number of hidden neurons\n",
    "        print '\\tTesting', h, 'neurons...'\n",
    "        nn = mlp.MLP([13,h,1], 'tanh')\n",
    "        for i in np.arange(N_TESTS):                                        # looping the tests\n",
    "            temp1, temp2 = cv.k_fold_cross_validation(nn,\n",
    "                                                      dataset,\n",
    "                                                      k=K,\n",
    "                                                      learning_rate=LEARNING_RATE,\n",
    "                                                      momentum=MOMENTUM,\n",
    "                                                      epochs=e)\n",
    "            MSE_train[i_h, i_e, i] = temp1\n",
    "            MSE_test[i_h, i_e, i] = temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE_train_mean = np.mean(MSE_train, axis=2)\n",
    "MSE_test_mean = np.mean(MSE_test, axis=2)\n",
    "MSE_train_sd = np.std(MSE_train, axis=2)\n",
    "MSE_test_sd = np.std(MSE_test, axis=2)\n",
    "\n",
    "v_min = min(np.min(MSE_train_mean), np.min(MSE_test_mean))\n",
    "v_max = max(np.max(MSE_train_mean), np.max(MSE_test_mean))\n",
    "\n",
    "pl.figure(figsize=(15,6))\n",
    "for i_e, e in enumerate(EPOCHS):\n",
    "    pl.subplot(1,3,i_e+1)\n",
    "    pl.fill_between(N_NEURONS, MSE_train_mean[:,i_e], MSE_train_mean[:,i_e]+MSE_train_sd[:,i_e], facecolor='blue', alpha=0.5, label='Train')\n",
    "    pl.fill_between(N_NEURONS, MSE_train_mean[:,i_e], MSE_train_mean[:,i_e]-MSE_train_sd[:,i_e], facecolor='blue', alpha=0.5)\n",
    "    pl.fill_between(N_NEURONS, MSE_test_mean[:,i_e], MSE_test_mean[:,i_e]+MSE_test_sd[:,i_e], facecolor='red', alpha=0.5, label='Test')\n",
    "    pl.fill_between(N_NEURONS, MSE_test_mean[:,i_e], MSE_test_mean[:,i_e]-MSE_test_sd[:,i_e], facecolor='red', alpha=0.5)\n",
    "    pl.ylim(0.95*v_min,1.05*v_max)\n",
    "    pl.ylabel('MSE')\n",
    "    pl.xlabel('Number of hidden neurons')\n",
    "    pl.title(str(K)+'-fold cross-validation with '+str(e)+' epochs')\n",
    "    pl.legend()\n",
    "    pl.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the number of epochs and the number of hidden neurons at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE_train = np.zeros((len(N_NEURONS), EPOCHS))\n",
    "MSE_test = np.zeros((len(N_NEURONS), EPOCHS))\n",
    "\n",
    "for i_h, h in enumerate(N_NEURONS):                                     # looping the number of hidden neurons\n",
    "    print '\\tTesting', h, 'neurons...'\n",
    "    nn = mlp.MLP([13,h,1], 'tanh')\n",
    "    temp1, temp2 = cv.k_fold_cross_validation_per_epoch(nn,\n",
    "                                                        dataset,\n",
    "                                                        k=K,\n",
    "                                                        learning_rate=LEARNING_RATE,\n",
    "                                                        momentum=MOMENTUM,\n",
    "                                                        epochs=EPOCHS)\n",
    "    MSE_train[i_h, :] = temp1\n",
    "    MSE_test[i_h, :] = temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min(np.min(MSE_train), np.min(MSE_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#v_min = min(np.min(MSE_train), np.min(MSE_test))\n",
    "v_min = 0.1   # tune these values to enhance visualization\n",
    "v_max = 1\n",
    "\n",
    "pl.figure(figsize=(15,8))\n",
    "pl.subplot(2,1,1)\n",
    "pl.imshow(MSE_train, vmin=v_min, vmax=v_max, aspect=3, interpolation='nearest')\n",
    "pl.yticks(np.arange(len(N_NEURONS)), N_NEURONS)\n",
    "pl.xlabel('Epochs')\n",
    "pl.ylabel('Number of hidden Neurons')\n",
    "pl.title('Training')\n",
    "pl.colorbar()\n",
    "pl.subplot(2,1,2)\n",
    "pl.imshow(MSE_test, vmin=v_min, vmax=v_max, aspect=3, interpolation='nearest')\n",
    "pl.yticks(np.arange(len(N_NEURONS)), N_NEURONS)\n",
    "pl.xlabel('Epochs')\n",
    "pl.ylabel('Number of hidden Neurons')\n",
    "pl.title('Test')\n",
    "pl.colorbar()\n",
    "pl.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe un grand pic d'erreur à 8 neurones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MSE_train, MSE_test, conf_mat = cv.k_fold_cross_validation(nn,\n",
    "                                                          dataset,\n",
    "                                                          k=K,\n",
    "                                                          learning_rate=LEARNING_RATE,\n",
    "                                                          momentum=MOMENTUM,\n",
    "                                                          epochs=80,\n",
    "                                                          threshold=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'MSE training: ', MSE_train\n",
    "print 'MSE test: ', MSE_test\n",
    "print 'Confusion matrix:'\n",
    "print conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l'erreur est très élevée ce qui signifie qu'il est très dur de départager les données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but ici est de voir à quel point le réseau de neurones arrive à distinguer des échantillons très proches, en prenant des enfants de 3 et 7 ans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_3yoFiles = []\n",
    "_7yoFiles = []\n",
    "\n",
    "for f in files:\n",
    "    if f.startswith(\"nk3\"):\n",
    "        _3yoFiles.append(wav.read(BASE_DIR + f))\n",
    "    if f.startswith(\"nk7\"):\n",
    "        _7yoFiles.append(wav.read(BASE_DIR + f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_3yoCeps = []\n",
    "for f in _3yoFiles:\n",
    "    _3yoCeps.append(mfcc(f[1], fs=f[0])[0])\n",
    "\n",
    "_7yoCeps = []\n",
    "for f in _7yoFiles:\n",
    "    _7yoCeps.append(mfcc(f[1], fs=f[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_3yoMeanCeps = []\n",
    "for c in naturalCeps:\n",
    "    _3yoMeanCeps.append(np.mean(c, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_7yoMeanCeps = []\n",
    "for c in naturalCeps:\n",
    "    _7yoMeanCeps.append(np.mean(c, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dsf = np.array(map(lambda x: np.append(x, 1), _3yoMeanCeps))\n",
    "dsm = np.array(map(lambda x: np.append(x, -1), _7yoMeanCeps))\n",
    "dataset = np.append(dsf, dsm, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_INITS = 10\n",
    "EPOCHS = 100\n",
    "N_NEURONS = [2, 4, 8, 16, 32]\n",
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE = np.zeros((len(N_NEURONS), N_INITS, EPOCHS))\n",
    "\n",
    "for i_h, h in enumerate(N_NEURONS):                                     # looping the number of hidden neurons\n",
    "    print 'Testing', h, 'neurons...'\n",
    "    nn = mlp.MLP([13,h,2], 'tanh')\n",
    "    for i in np.arange(N_INITS):                                        # looping the initializations\n",
    "        nn.init_weights()\n",
    "        \n",
    "        MSE[i_h, i, :] = nn.fit((dataset[:,0:13], dataset[:,13:15]),\n",
    "                                learning_rate=LEARNING_RATE,\n",
    "                                momentum=MOMENTUM,\n",
    "                                epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pl.figure(figsize=(15,12))\n",
    "p_count = 0\n",
    "for lim in [100, 50, 20]:\n",
    "    for n in np.arange(MSE.shape[0]):\n",
    "        p_count += 1\n",
    "        pl.subplot(3,MSE.shape[0], p_count)\n",
    "        for i in np.arange(MSE.shape[1]):\n",
    "            pl.plot(MSE[n,i,:], c='b')\n",
    "        pl.ylim(0,1)\n",
    "        pl.xlim(0,lim)\n",
    "        pl.xlabel('Epochs')\n",
    "        pl.ylabel('MSE')\n",
    "        pl.title(str(N_NEURONS[n]) + ' neurons')\n",
    "        pl.grid()\n",
    "pl.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variation d'epochs n'a aucune influence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the number of hidden neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = [20, 50, 100]\n",
    "K = 5\n",
    "N_TESTS = 10\n",
    "N_NEURONS = [2, 4, 6, 8, 10, 15, 20, 30, 40, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE_train = np.zeros((len(N_NEURONS), len(EPOCHS), N_TESTS))\n",
    "MSE_test = np.zeros((len(N_NEURONS), len(EPOCHS), N_TESTS))\n",
    "\n",
    "for i_e, e in enumerate(EPOCHS):                                            # looping the number of epochs\n",
    "    print 'Testing with', e, 'epochs...'\n",
    "    for i_h, h in enumerate(N_NEURONS):                                     # looping the number of hidden neurons\n",
    "        print '\\tTesting', h, 'neurons...'\n",
    "        nn = mlp.MLP([13,h,1], 'tanh')\n",
    "        for i in np.arange(N_TESTS):                                        # looping the tests\n",
    "            temp1, temp2 = cv.k_fold_cross_validation(nn,\n",
    "                                                      dataset,\n",
    "                                                      k=K,\n",
    "                                                      learning_rate=LEARNING_RATE,\n",
    "                                                      momentum=MOMENTUM,\n",
    "                                                      epochs=e)\n",
    "            MSE_train[i_h, i_e, i] = temp1\n",
    "            MSE_test[i_h, i_e, i] = temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE_train_mean = np.mean(MSE_train, axis=2)\n",
    "MSE_test_mean = np.mean(MSE_test, axis=2)\n",
    "MSE_train_sd = np.std(MSE_train, axis=2)\n",
    "MSE_test_sd = np.std(MSE_test, axis=2)\n",
    "\n",
    "v_min = min(np.min(MSE_train_mean), np.min(MSE_test_mean))\n",
    "v_max = max(np.max(MSE_train_mean), np.max(MSE_test_mean))\n",
    "\n",
    "pl.figure(figsize=(15,6))\n",
    "for i_e, e in enumerate(EPOCHS):\n",
    "    pl.subplot(1,3,i_e+1)\n",
    "    pl.fill_between(N_NEURONS, MSE_train_mean[:,i_e], MSE_train_mean[:,i_e]+MSE_train_sd[:,i_e], facecolor='blue', alpha=0.5, label='Train')\n",
    "    pl.fill_between(N_NEURONS, MSE_train_mean[:,i_e], MSE_train_mean[:,i_e]-MSE_train_sd[:,i_e], facecolor='blue', alpha=0.5)\n",
    "    pl.fill_between(N_NEURONS, MSE_test_mean[:,i_e], MSE_test_mean[:,i_e]+MSE_test_sd[:,i_e], facecolor='red', alpha=0.5, label='Test')\n",
    "    pl.fill_between(N_NEURONS, MSE_test_mean[:,i_e], MSE_test_mean[:,i_e]-MSE_test_sd[:,i_e], facecolor='red', alpha=0.5)\n",
    "    pl.ylim(0.95*v_min,1.05*v_max)\n",
    "    pl.ylabel('MSE')\n",
    "    pl.xlabel('Number of hidden neurons')\n",
    "    pl.title(str(K)+'-fold cross-validation with '+str(e)+' epochs')\n",
    "    pl.legend()\n",
    "    pl.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variation du nombre de neurones n'a aucune influence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the number of epochs and the number of hidden neurons at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE_train = np.zeros((len(N_NEURONS), EPOCHS))\n",
    "MSE_test = np.zeros((len(N_NEURONS), EPOCHS))\n",
    "\n",
    "for i_h, h in enumerate(N_NEURONS):                                     # looping the number of hidden neurons\n",
    "    print '\\tTesting', h, 'neurons...'\n",
    "    nn = mlp.MLP([13,h,1], 'tanh')\n",
    "    temp1, temp2 = cv.k_fold_cross_validation_per_epoch(nn,\n",
    "                                                        dataset,\n",
    "                                                        k=K,\n",
    "                                                        learning_rate=LEARNING_RATE,\n",
    "                                                        momentum=MOMENTUM,\n",
    "                                                        epochs=EPOCHS)\n",
    "    MSE_train[i_h, :] = temp1\n",
    "    MSE_test[i_h, :] = temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min(np.min(MSE_train), np.min(MSE_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#v_min = min(np.min(MSE_train), np.min(MSE_test))\n",
    "v_min = 0.1   # tune these values to enhance visualization\n",
    "v_max = 1\n",
    "\n",
    "pl.figure(figsize=(15,8))\n",
    "pl.subplot(2,1,1)\n",
    "pl.imshow(MSE_train, vmin=v_min, vmax=v_max, aspect=3, interpolation='nearest')\n",
    "pl.yticks(np.arange(len(N_NEURONS)), N_NEURONS)\n",
    "pl.xlabel('Epochs')\n",
    "pl.ylabel('Number of hidden Neurons')\n",
    "pl.title('Training')\n",
    "pl.colorbar()\n",
    "pl.subplot(2,1,2)\n",
    "pl.imshow(MSE_test, vmin=v_min, vmax=v_max, aspect=3, interpolation='nearest')\n",
    "pl.yticks(np.arange(len(N_NEURONS)), N_NEURONS)\n",
    "pl.xlabel('Epochs')\n",
    "pl.ylabel('Number of hidden Neurons')\n",
    "pl.title('Test')\n",
    "pl.colorbar()\n",
    "pl.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que le réseau de neurones n'arrive rien à distinguer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MSE_train, MSE_test, conf_mat = cv.k_fold_cross_validation(nn,\n",
    "                                                          dataset,\n",
    "                                                          k=K,\n",
    "                                                          learning_rate=LEARNING_RATE,\n",
    "                                                          momentum=MOMENTUM,\n",
    "                                                          epochs=80,\n",
    "                                                          threshold=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'MSE training: ', MSE_train\n",
    "print 'MSE test: ', MSE_test\n",
    "print 'Confusion matrix:'\n",
    "print conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on pouvait s'en douter, sur un set de données ou même l'oreille humaine a de la peine, un réseau de neurones n'a aucune chance de trouver quoi que ce soit. Ceci peut être partiellement dû au fait que le mfcc ne décrit peut-être pas assez précisément les sons pour une telle application, et qu'il manque donc de feature."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
